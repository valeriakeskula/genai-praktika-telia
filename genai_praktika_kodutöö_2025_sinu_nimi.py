from pdfminer.high_level import extract_text
from bs4 import BeautifulSoup
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import google.ai.generativelanguage as glm

import google.generativeai as genai
from sentence_transformers import SentenceTransformer, util
from sklearn.feature_extraction.text import TfidfVectorizer

import numpy as np
from sentence_transformers import util

import os
from dotenv import load_dotenv

from random import choice
import time


# -*- coding: utf-8 -*-
"""genai_praktika_kodutöö_2025_SINU_NIMI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PYRE8md6rMW9BRpJ7TQ5T2sRfnE5gR5r

# Kodutöö GenAI praktika kandidaadile
Aprill 2025

**Kandideerija nimi:** VALERIA KESKÜLA


# 1. ülesanne

## 1.1 alamülesanne

Lae alla need 2 PDF faili:

https://www.telia.ee/images/documents/TELIA_raport_EST_2024.pdf
https://www.telia.ee/images/documents/hinnakirjad/est/telia_eesti_ariteenused_yldosa.pdf

Samuti lae alla selle veebilehe sisu HTML formaadis:
https://digitark.telia.ee/era/rohde-schwarz-eestis-on-mobiilse-interneti-kiirus-huppeliselt-kasvanud/
"""

import requests

urls = [
    "https://www.telia.ee/images/documents/TELIA_raport_EST_2024.pdf",
    "https://www.telia.ee/images/documents/hinnakirjad/est/telia_eesti_ariteenused_yldosa.pdf",
    "https://digitark.telia.ee/era/rohde-schwarz-eestis-on-mobiilse-interneti-kiirus-huppeliselt-kasvanud/"
]

## PDF
pdf_filenames = ["TELIA_raport_EST_2024.pdf", "telia_ariteenused_yldosa.pdf"]

for url, filename in zip(urls[:2], pdf_filenames):
    response = requests.get(url)
    with open(filename, "wb") as f:
        f.write(response.content)
print("HTML-fail on alla laaditud.")


## HTML
html_url = urls[2]
response = requests.get(html_url)

with open("telia_artikkel.html", "w", encoding="utf-8") as f:
    f.write(response.text)

print("HTML-fail on alla laaditud.")


## 1.2 alamülesanne

# PDF tekstiks
pdf_files = ["TELIA_raport_EST_2024.pdf", "telia_ariteenused_yldosa.pdf"]
for pdf in pdf_files:
    text = extract_text(pdf)
    with open(pdf.replace(".pdf", ".txt"), "w", encoding="utf-8") as f:
        f.write(text)
    print(f"\nEsimesed 2000 tähemärki failist {pdf}:")
    print(text[:2000])
    print("\n" + "-"*80 + "\n")


# HTML tekstiks
with open("telia_artikkel.html", "r", encoding="utf-8") as f:
    soup = BeautifulSoup(f, "html.parser")
    html_text = soup.get_text()

with open("telia_artikkel.txt", "w", encoding="utf-8") as f:
    f.write(html_text)

print("\nEsimesed 2000 tähemärki HTML artiklist:")
print(html_text[:2000])


""" Enamus infot leidisin siin: 
https://stackoverflow.com/questions/26494211/extracting-text-from-a-pdf-file-using-pdfminer-in-python

- seetõttu valisin pdfminer.six, kuna see on sobiv keerukamate PDF dokumentide tekstist välja toomiseks. 

HTML-faili jaoks kasutasin BeautifulSoup, kuna see võimaldab lihtsalt HTML sisu puhastamist ja 
tekstiks teisendamist. Olen ka varem sellest kuulnud ja näinud tutorials YouTube'is."""


## 1.3 alamülesanne

def tekst_jupidena(tekst, pikkus=500):
    jupid = []

    for i in range(0, len(tekst), pikkus):
        jupp = tekst[i:i + pikkus]
        jupid.append(jupp)
    return jupid




failid = ["TELIA_raport_EST_2024.txt", "telia_ariteenused_yldosa.txt", "telia_artikkel.txt"]
nimed = ["TELIA raport", "Äriteenuste üldosa", "Artikkel"]

for fail, nimi in zip(failid, nimed):
    with open(fail, "r", encoding="utf-8") as f:
        sisu = f.read()
        jupid = tekst_jupidena(sisu, 500)
        ## print("EX2")
        print(f"\n--- {nimi} ---")
        print("Jupp 1:\n", jupid[0][:300], "...")
        print("\nJupp 2:\n", jupid[1][:300], "...")


"""Valisin jupitamise 500 tähemärgi kaupa, sest see on lihtne ja tagab, et igas jupis on piisavalt teksti, 
kuid see ei lähe liiga pikaks. Sobib hästi edasiseks töötlemiseks."""

## 1.4 alamülesanne - vektoriseerimine
def lae_tekstijupid(failinimed, pikkus=500):
    jupid = []
    for fail in failinimed:
        with open(fail, "r", encoding="utf-8") as f:
            tekst = f.read()
            for i in range(0, len(tekst), pikkus):
                jupid.append(tekst[i:i + pikkus])
    return jupid

failid = ["TELIA_raport_EST_2024.txt", "telia_ariteenused_yldosa.txt", "telia_artikkel.txt"]
tekstijupid = lae_tekstijupid(failid)

mudel = SentenceTransformer("paraphrase-MiniLM-L6-v2")
vektorid = mudel.encode(tekstijupid)



print("Vektor 1 (esimesed 5 väärtust):", vektorid[0][:5])
print("Vektor 2 (esimesed 5 väärtust):", vektorid[1][:5])


"""Valisin paraphrase-MiniLM-L6-v2, kuna see on väiksem mudel HuggingFace’ist 
ning töötab ka  eestikeelse tekstiga ja on kiire vektorite loomiseks.

https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2
"""


## 1.5 alamülesanne - vektorotsing
fraasid = [
    "Mis on allalaadimiskiirus maanteedel?",
    "Mis on vana uueks?",
    "Kes on Andre Visse?"
]

fraasi_vektorid = mudel.encode(fraasid)
tulemused = []



for i, fv in enumerate(fraasi_vektorid):
    print(f"\n--- Tulemused fraasile: '{fraasid[i]}' ---")
    sarnasused = util.cos_sim(fv, vektorid)[0]
    top_idx = np.argsort(-sarnasused)[:3]
    for idx in top_idx:
        print(f"\nJupp {idx + 1} (sarnasus {sarnasused[idx]:.2f}):")
        print(tekstijupid[idx][:300], "...")


## 1.6 alamülesanne - hübriidotsing
estonian_stopwords = [
    "ja", "on", "see", "et", "ei", "kas", "või", "kuid", "ka", "oma", "mis",
    "kelle", "seda", "kui", "olen", "me", "te", "nad", "mida", "neid", "meid",
    "kes", "mille", "selle", "milline", "seal", "siin", "olnud", "saab", "nende",
    "pole", "sellel", "siis", "neist", "oleks", "kasutatakse", "ainult", "võib", "enam",
    "üks", "rohkem", "vähem", "tuleb", "enda", "neile", "tema", "nendele", "aga", "ning",
    "võimalik", "selleks", "sealhulgas", "samas", "vahel", "mõned", "teatud", "seejärel"
]

tfidf = TfidfVectorizer(stop_words=estonian_stopwords)

tfidf_matrix = tfidf.fit_transform(tekstijupid)

def hybridi_otsing(küsimus, top_k=3):


    # Vektorotsing
    küsimus_vektor = mudel.encode([küsimus])
    sarnasus_v = util.cos_sim(küsimus_vektor, vektorid)[0]

    # TF-IDF
    tfidf_vector = tfidf.transform([küsimus])
    sarnasus_t = tfidf_matrix.dot(tfidf_vector.T).toarray().ravel()

    # Kombineeritud
    kombineeritud_skoor = sarnasus_v.numpy() + sarnasus_t
    top_idx = np.argsort(-kombineeritud_skoor)[:top_k]


    print(f"\nFraas: '{küsimus}'")
    for i in top_idx:
        print(f"\nJupp {i + 1} (skoor {kombineeritud_skoor[i]:.2f}):")
        print(tekstijupid[i][:300], "...")

for fraas in fraasid:
    hybridi_otsing(fraas)

"""Ma arvan, et vektorotsing oli liiga üldine, hübriidotsing suudab anda täpsemaid tulemusi."""


## 1.7 alamülesanne
mod = "google/flan-t5-small"
tokenizer = AutoTokenizer.from_pretrained(mod)
model = AutoModelForSeq2SeqLM.from_pretrained(mod)

def vasta_küsimusele(küsimus):
    inputs = tokenizer(küsimus, return_tensors="pt")
    output = model.generate(**inputs, max_new_tokens=80)
    vastus = tokenizer.decode(output[0], skip_special_tokens=True)
    return vastus

print("\nVastused ilma kontekstita:")
for fraas in fraasid:
    print(f"\n {fraas}")
    print(vasta_küsimusele(fraas))

    """Valisin flan-t5-small, kuna see on väike, töötab kiirelt CPU peal ja toetab mitut keelt, ka eesti keelt,
    kuid mõnikord vastus pole nii täpselt nagu sooviks"""

## 1.8 alamülesanne
load_dotenv()
genai_api_key = os.getenv("GEMINI_API_KEY")

genai.configure(api_key=genai_api_key)

print("Saadaval mudelid:")
for m in genai.list_models():
    print(m.name)

model = genai.GenerativeModel("models/gemini-1.5-pro-latest")
response = model.generate_content("Mis on digikelts?")
print(response.text)



valikud = ["models/gemini-1.5-pro", "models/gemini-1.5-flash"]

def küsi_geminilt(prompt):
    valitud_mudel = genai.GenerativeModel(model_name=choice(valikud))
    print(f"❖ Valitud mudel: {valitud_mudel._model_name}")  # vabatahtlik
    response = valitud_mudel.generate_content(prompt)
    return response.text



def küsi_geminilt_kontekstiga(küsimus):
    küsimus_vektor = mudel.encode([küsimus])
    sarnasus_v = util.cos_sim(küsimus_vektor, vektorid)[0]
    tfidf_vector = tfidf.transform([küsimus])
    sarnasus_t = tfidf_matrix.dot(tfidf_vector.T).toarray().ravel()
    kombineeritud = sarnasus_v.numpy() + sarnasus_t
    top_idx = np.argsort(-kombineeritud)[:3]

    kontekst = "\n".join([tekstijupid[i] for i in top_idx])
    prompt = f"Vasta küsimusele: '{küsimus}'\nTähtis taustinfo:\n{kontekst}"
    return küsi_geminilt(prompt)



print("\n Gemini vastused:")
for fraas in fraasid:
    print(f"\n{fraas}")
    print(küsi_geminilt(fraas))
    time.sleep(60)

print("\n Gemini vastused koos kontekstiga:")
for fraas in fraasid:
    print(f"\n{fraas}")
    try:
        print(küsi_geminilt_kontekstiga(fraas))
    except Exception as e:
        print(f"Tekkis viga: {e}")
    time.sleep(60)

    """Konteksti lisamine parandab täpsust – mudelil on rohkem infot. 
    Kuid problimiks on see, et osa vastuseid võib sisaldada vananenud andmeid."""



## Ülesanne 2

# .env fail
load_dotenv()
genai_api_key = os.getenv("GEMINI_API_KEY")
weather_api_key = os.getenv("OPENWEATHER_API_KEY")

# Gemini
genai.configure(api_key=genai_api_key)
model = genai.GenerativeModel("models/gemini-1.5-pro-latest")



# OpenWeather
def get_weather(city: str):
    url = f"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={weather_api_key}&units=metric&lang=et"
    response = requests.get(url)
    data = response.json()

    if response.status_code == 200:
        temp = data["main"]["temp"]
        desc = data["weather"][0]["description"]
        return f"Ilm {city} linnas: {temp}°C, {desc}."
    else:
        return f"Ilmaandmeid ei leitud linnale {city}."



# Funk., mis laseb Gemini-le ise otsustada linna ja siis kasutab tööriista
def gemini_küsib_ja_kasutab_tööriista(prompt):
    response = model.generate_content(f"{prompt} Kirjuta ainult linna nimi vastuses.")
    city = response.text.strip()
    print(f"Gemini pakkus linna: {city}")
    ilm = get_weather(city)
    return ilm


# Näide
# print(gemini_küsib_ja_kasutab_tööriista("Sooviksin teada, milline on ilm Eesti lõunaosas."))

"""Minu tööriista kasutav keelemudel suudab esmalt tuvastada linnanime kasutaja küsimusest 
ning seejärel kasutada OpenWeather API-d, et tuua reaalajas ilmainfo. 
Selline lähenemine võimaldab keelemudelil anda täpse ja ajakohase vastuse, 
mida saab tööriista abil teada. Selline lahendus sobib hästi ilmarakenduse jaoks."""


## Tagasiside
"""Minu jaoks olid lihtsamad need ülesanded, kus tuli faile alla laadida ja tekstiks konverteerida –
 nende jaoks oli olemas palju näiteid ja info oli selgelt arusaadav. Samuti meeldis mulle tekstijuppideks jagamine ja
  vektorite loomine, sest see tundus loogiline ja matemaatiliselt huvitav.

Keerulisemaks osutus Gemini API seadistamine ja .env failide kasutamine, 
kuna see oli uus teema ja nõudis rohkem tehnilist mõistmist. Samuti oli keeruline hübriidotsingu loogika realiseerimine,
 aga tänu selgitustele sain sellest lõpuks hästi aru."""
